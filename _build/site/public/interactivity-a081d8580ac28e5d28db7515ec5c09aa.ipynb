{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56cecf24-bf14-476a-9d10-c3360c7d5b86",
   "metadata": {},
   "source": [
    "# Timecourse with interactivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8e6632",
   "metadata": {},
   "source": [
    "## Interactivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7199c242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2571f6d713924f64bfcaa7c69e6b2afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, description='Number:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "import re\n",
    "import glob\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create a slider widget\n",
    "slider = widgets.IntSlider(\n",
    "    value=0,            # Initial value\n",
    "    min=0,              # Minimum value\n",
    "    max=100,            # Maximum value\n",
    "    step=1,             # Step size\n",
    "    description='Number:',  # Label for the slider\n",
    "    continuous_update=True  # Update output continuously as the slider moves\n",
    ")\n",
    "\n",
    "# Create a function to update the greeting\n",
    "def update_greeting(change):\n",
    "    change[\"new\"]\n",
    "    # print(f'Hello! You selected the number: {change[\"new\"]}')\n",
    "\n",
    "# Attach the function to the slider widget\n",
    "slider.observe(update_greeting, names='value')\n",
    "\n",
    "# Display the slider widget\n",
    "display(slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d88aacb",
   "metadata": {},
   "source": [
    "# Time course measurements\n",
    "\n",
    "A shared understanding of how to interpret data from CFE systems would speed the development of measurements and standards towards improved reproducibility and address challenges in interpreting and comparing existing and future data, including data from failed experiments. Workshop participants agreed that time-course measurements of the product expressed in the CFE reaction should be favored over endpoint measurements, despite the time, labor, and costs involved, to obtain a more complete and informative view of a CFE reaction. Whenever possible, measurements should be reported as a reduced quantity, such as a mean value, with uncertainty (Figure 2A) and include a baseline from negative control measurements. Several recent studies have commented on metrics available from a time-course measurement of protein expression in a CFE workflow, for example, for the purpose of reaction optimization [ref] and the development of predictive modeling tools [ref]. Workshop participants emphasized several of these metrics, displayed below in Figure 2\n",
    "\n",
    "\n",
    "- Maximum yield of product expressed;\n",
    "- $t_{max}$ Time to reach the maximum yield of product expressed, as the time from the start of the measurement to the time to reach the maximum yield;\n",
    "- $ v_{max}$ Maximum rate of product expression, as the maximum linear rate of production;\n",
    "- Lag time, as the time from the start of the measurement to the time to reach the maximum rate of expression;\n",
    "- Inflection time, as the time from the start of the measurement to the time at which the rate of product expression begins to decrease;\n",
    "- Percent decline, as a decrease in the amount of product expressed from the maximum yield; and,\n",
    "- Time to percent decline, as the amount of time from the start of the measurement to the time to reach a predefined decrease in the yield of product expressed after having reached its maximum yield of product expressed.\n",
    "\n",
    "## Workflow\n",
    "\n",
    "### Platemap\n",
    "\n",
    ":::{note}\n",
    "Ideally, we would have a tool that (1) let's people describe experiments in a standardized way (spec lang), (2) that can then be mapped onto a platemap, and (3) displayed in part or whole in this section [this might be an interesting place for a widget to explore the parameters of the experiment]\n",
    ":::\n",
    "\n",
    "This is text describing the context of the experiment. There a few scenarios where this text can end up here. We can imagine users working in jupyterhub typing directly or its copy and pasted in from an experimental notebook. In this particular case, we have two experiments on testing the effect of DNA concentration and a second experiment comparing different DNA constrcuts - the infamous artifact 11 (AR-11)\n",
    " \n",
    ":::{dropdown} Dropdown Title\n",
    ":open:\n",
    "\n",
    ":::{table} Experimental conditions studied\n",
    ":label: tbl:platemap\n",
    "![](#pd:platemap)\n",
    ":::\n",
    "\n",
    ":::\n",
    "\n",
    "### Analysis\n",
    "\n",
    "One thing that might be interesting to show here would be a progression from end-point analysis, unannotated timeseries, time series annotations, and then exploring the kinetic parameters. \n",
    "\n",
    "```{code} python\n",
    ":label: code:filter-platemap\n",
    ":caption: filter the plate map to select for a specific experiment\n",
    "# experiment -> \"DNA Concentration\"\n",
    "data_concentration = data[data[\"Experiment\"] == \"DNA Concentration\"]\n",
    "```\n",
    "\n",
    "Here, [](#code:filter-platemap) is used to generate the following figure using these [specific lines](https://github.com/bnext-bio/nucleus/blob/main/cdk/analysis/cytosol-analysis/cytosol-kinetics.ipynb#L563-L565) of code from the cytosol analysis toolkit. This might be useful for instance if we're showcasing a new feature in the codebase and we want to make a tight connection between code and function, inviting engagement.\n",
    "\n",
    "The immediate advantage of this notebook over our existing way of publishing is that the figure is unambiguously linked to the data and code used to generate it. In this particular case, the sample data is co-located in the directory used to generate the HTML. Another approach might be to pull the data programmatically from an archive like zenodo.\n",
    "\n",
    ":::{admonition} Pulling data directly from an archive\n",
    ":class: dropdown\n",
    "```{code} python\n",
    "# this workflow would also work for OSF\n",
    "from zenodo_client import Zenodo\n",
    "\n",
    "zenodo = Zenodo(access_token=token)\n",
    "OOH_NA_NA_RECORD = '13852103'\n",
    "\n",
    "platemap_file = '20240916-platemap.xlsx'\n",
    "data_file = 'timecourse.csv'\n",
    "\n",
    "data = zenodo.download_latest(OOH_NA_NA_RECORD, data_file)\n",
    "platemap = zenodo.download_latest(OOH_NA_NA_RECORD, platemap_file)\n",
    "```\n",
    ":::\n",
    "\n",
    ":::{figure} #plt:expression-kinetics-simple\n",
    ":label: fig:expression kinetics\n",
    ":align: center\n",
    "The plasmid pT7-deGFP (AR-11) is swept from 0-100 ng/$\\mu$L in the PURE system\n",
    ":::\n",
    "\n",
    "Now, we can showcase the kinetic analysis tool by showing a single timeseries selected from the above experiment where the extracted features are annotated. It was a bit annoying to extract one plot from the FacetGrid. Instead, I reduced the DataFrame\n",
    "\n",
    ":::{admonition} Plotting a single annotated kinetic trace\n",
    ":class: dropdown\n",
    "```python\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "single_well = data_concentration[data_concentration[\"Well\"] == \"B1\"]\n",
    "\n",
    "single_well_kinetics = kinetic_analysis(data=single_well, data_column=\"Data\", time_cutoff=15000)\n",
    "g = sns.FacetGrid(single_well_kinetics, col=\"Well\", col_wrap=2, sharey=False, height=4, aspect=1.5)\n",
    "g.map_dataframe(plot_kinetics, y=\"Data\", show_fit=True, show_velocity=False, annotate=True)\n",
    "```\n",
    ":::\n",
    "\n",
    ":::{figure} #plt:single-kinetics\n",
    ":label: fig:kinetics-plot\n",
    ":align: center\n",
    "Annotated timeseries for pT7-deGFP (AR-11) in PURE at a concentration of 100 ng/$\\mu$L\n",
    ":::\n",
    "\n",
    "Of course, the figure isn't really what's valuable. Ultimately, we want to associate the dimension-reduced kinetic parameters with the experimental specification. We can push this to a database like SeqBase where the *input* sequence and experimental specification are coupled to the *output* kinetic parameters. \n",
    "\n",
    "Other types of data for non-fluorescent data will have to be developed over time. \n",
    "\n",
    ":::{table} Combined experimental specification with kinetic parameters extracted from data.\n",
    ":label: tbl:platemap\n",
    ":align: center\n",
    "![](#pd:kinetics)\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "912ec25a-c91f-4a2e-a227-2375c69ee38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9960ba16754c4837a9244299e0e4b4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, description='Number:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77f474f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
